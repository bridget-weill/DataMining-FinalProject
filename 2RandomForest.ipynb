{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Random Forest__\n",
    "## Pipeline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdministrativeSkew</th>\n",
       "      <th>Administrative_DurationSkew</th>\n",
       "      <th>InformationalSkew</th>\n",
       "      <th>Informational_DurationSkew</th>\n",
       "      <th>ProductRelatedSkew</th>\n",
       "      <th>ProductRelated_DurationSkew</th>\n",
       "      <th>BounceRatesSkew</th>\n",
       "      <th>ExitRatesSkew</th>\n",
       "      <th>PageValuesSkew</th>\n",
       "      <th>SpecialDay_0.0</th>\n",
       "      <th>...</th>\n",
       "      <th>VisitorType_New_Visitor</th>\n",
       "      <th>VisitorType_Other</th>\n",
       "      <th>VisitorType_Returning_Visitor</th>\n",
       "      <th>Weekend_False</th>\n",
       "      <th>Weekend_True</th>\n",
       "      <th>SeasonBins_1</th>\n",
       "      <th>SeasonBins_2</th>\n",
       "      <th>SeasonBins_3</th>\n",
       "      <th>SeasonBins_4</th>\n",
       "      <th>RevenueEnc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.486759</td>\n",
       "      <td>0.198950</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.031306</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.177272</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.486759</td>\n",
       "      <td>0.198950</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.462351</td>\n",
       "      <td>0.190387</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.012429</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.401902</td>\n",
       "      <td>0.136293</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AdministrativeSkew  Administrative_DurationSkew  InformationalSkew  \\\n",
       "0                -0.0                         -0.0               -0.0   \n",
       "1                -0.0                         -0.0               -0.0   \n",
       "2                -0.0                         -0.0               -0.0   \n",
       "3                -0.0                         -0.0               -0.0   \n",
       "4                -0.0                         -0.0               -0.0   \n",
       "\n",
       "   Informational_DurationSkew  ProductRelatedSkew  \\\n",
       "0                        -0.0            0.001399   \n",
       "1                        -0.0            0.002761   \n",
       "2                        -0.0            0.001399   \n",
       "3                        -0.0            0.002761   \n",
       "4                        -0.0            0.012429   \n",
       "\n",
       "   ProductRelated_DurationSkew  BounceRatesSkew  ExitRatesSkew  \\\n",
       "0                    -0.000000         0.486759       0.198950   \n",
       "1                     0.031306        -0.000000       0.177272   \n",
       "2                    -0.000000         0.486759       0.198950   \n",
       "3                     0.006454         0.462351       0.190387   \n",
       "4                     0.089834         0.401902       0.136293   \n",
       "\n",
       "   PageValuesSkew  SpecialDay_0.0  ...  VisitorType_New_Visitor  \\\n",
       "0            -0.0               1  ...                        0   \n",
       "1            -0.0               1  ...                        0   \n",
       "2            -0.0               1  ...                        0   \n",
       "3            -0.0               1  ...                        0   \n",
       "4            -0.0               1  ...                        0   \n",
       "\n",
       "   VisitorType_Other  VisitorType_Returning_Visitor  Weekend_False  \\\n",
       "0                  0                              1              1   \n",
       "1                  0                              1              1   \n",
       "2                  0                              1              1   \n",
       "3                  0                              1              1   \n",
       "4                  0                              1              0   \n",
       "\n",
       "   Weekend_True  SeasonBins_1  SeasonBins_2  SeasonBins_3  SeasonBins_4  \\\n",
       "0             0             1             0             0             0   \n",
       "1             0             1             0             0             0   \n",
       "2             0             1             0             0             0   \n",
       "3             0             1             0             0             0   \n",
       "4             1             1             0             0             0   \n",
       "\n",
       "   RevenueEnc  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import metrics\n",
    "\n",
    "# load dataset\n",
    "rfdata = pd.read_csv('pipeline2.csv', header=0)\n",
    "rfdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AdministrativeSkew', 'Administrative_DurationSkew',\n",
       "       'InformationalSkew', 'Informational_DurationSkew',\n",
       "       'ProductRelatedSkew', 'ProductRelated_DurationSkew',\n",
       "       'BounceRatesSkew', 'ExitRatesSkew', 'PageValuesSkew',\n",
       "       'SpecialDay_0.0', 'SpecialDay_0.2', 'SpecialDay_0.4',\n",
       "       'SpecialDay_0.6', 'SpecialDay_0.8', 'SpecialDay_1.0',\n",
       "       'OperatingSystems_1', 'OperatingSystems_2', 'OperatingSystems_3',\n",
       "       'OperatingSystems_4', 'OperatingSystems_5', 'OperatingSystems_6',\n",
       "       'OperatingSystems_7', 'OperatingSystems_8', 'Browser_1',\n",
       "       'Browser_2', 'Browser_3', 'Browser_4', 'Browser_5', 'Browser_6',\n",
       "       'Browser_7', 'Browser_8', 'Browser_9', 'Browser_10', 'Browser_11',\n",
       "       'Browser_12', 'Browser_13', 'Region_1', 'Region_2', 'Region_3',\n",
       "       'Region_4', 'Region_5', 'Region_6', 'Region_7', 'Region_8',\n",
       "       'Region_9', 'TrafficType_1', 'TrafficType_2', 'TrafficType_3',\n",
       "       'TrafficType_4', 'TrafficType_5', 'TrafficType_6', 'TrafficType_7',\n",
       "       'TrafficType_8', 'TrafficType_9', 'TrafficType_10',\n",
       "       'TrafficType_11', 'TrafficType_12', 'TrafficType_13',\n",
       "       'TrafficType_14', 'TrafficType_15', 'TrafficType_16',\n",
       "       'TrafficType_17', 'TrafficType_18', 'TrafficType_19',\n",
       "       'TrafficType_20', 'VisitorType_New_Visitor', 'VisitorType_Other',\n",
       "       'VisitorType_Returning_Visitor', 'Weekend_False', 'Weekend_True',\n",
       "       'SeasonBins_1', 'SeasonBins_2', 'SeasonBins_3', 'SeasonBins_4',\n",
       "       'RevenueEnc'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfdata.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = ['AdministrativeSkew', 'Administrative_DurationSkew',\n",
    "       'InformationalSkew', 'Informational_DurationSkew',\n",
    "       'ProductRelatedSkew', 'ProductRelated_DurationSkew',\n",
    "       'BounceRatesSkew', 'ExitRatesSkew','PageValuesSkew',\n",
    "       'SpecialDay_0.0', 'SpecialDay_0.2', 'SpecialDay_0.4',\n",
    "       'SpecialDay_0.6', 'SpecialDay_0.8', 'SpecialDay_1.0',\n",
    "       'OperatingSystems_1', 'OperatingSystems_2', 'OperatingSystems_3',\n",
    "       'OperatingSystems_4', 'OperatingSystems_5', 'OperatingSystems_6',\n",
    "       'OperatingSystems_7', 'OperatingSystems_8', 'Browser_1',\n",
    "       'Browser_2', 'Browser_3', 'Browser_4', 'Browser_5', 'Browser_6',\n",
    "       'Browser_7', 'Browser_8', 'Browser_9', 'Browser_10', 'Browser_11',\n",
    "       'Browser_12', 'Browser_13', 'Region_1', 'Region_2', 'Region_3',\n",
    "       'Region_4', 'Region_5', 'Region_6', 'Region_7', 'Region_8',\n",
    "       'Region_9', 'TrafficType_1', 'TrafficType_2', 'TrafficType_3',\n",
    "       'TrafficType_4', 'TrafficType_5', 'TrafficType_6', 'TrafficType_7',\n",
    "       'TrafficType_8', 'TrafficType_9', 'TrafficType_10',\n",
    "       'TrafficType_11', 'TrafficType_12', 'TrafficType_13',\n",
    "       'TrafficType_14', 'TrafficType_15', 'TrafficType_16',\n",
    "       'TrafficType_17', 'TrafficType_18', 'TrafficType_19',\n",
    "       'TrafficType_20', 'VisitorType_New_Visitor', 'VisitorType_Other',\n",
    "       'VisitorType_Returning_Visitor', 'Weekend_False', 'Weekend_True',\n",
    "       'SeasonBins_1', 'SeasonBins_2', 'SeasonBins_3', 'SeasonBins_4']\n",
    "X = rfdata[feature_cols] # Features\n",
    "y = rfdata.RevenueEnc # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Predict the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf = RandomForestClassifier(random_state=200)\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.6027111574556829\n",
      "AUC: 0.7366664656838607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3126\n",
      "           1       0.75      0.50      0.60       573\n",
      "\n",
      "    accuracy                           0.90      3699\n",
      "   macro avg       0.83      0.74      0.77      3699\n",
      "weighted avg       0.89      0.90      0.89      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1_Score:\",metrics.f1_score(y_test, y_pred))\n",
    "print(\"AUC:\",metrics.roc_auc_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __SMOTE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "duplicate base class Sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-01065fdbc1a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_smote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/imblearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mover_sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/imblearn/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m in keras.\"\"\"\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBalancedBatchGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbalanced_batch_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/imblearn/keras/_generator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBalancedBatchGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mParentClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \"\"\"Create balanced batches when training a keras model.\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: duplicate base class Sequence"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state = 123) \n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=200)\n",
    "# fit the model with data\n",
    "clf.fit(X_train_smote,y_train_smote)\n",
    "# predict the model\n",
    "y_pred_smote=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred_smote)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"Blues\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1_Score:\",metrics.f1_score(y_test, y_pred_smote))\n",
    "print(\"AUC:\",metrics.roc_auc_score(y_test, y_pred_smote))\n",
    "print(classification_report(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Feature Selection in Scikit-learn__\n",
    "Find important features or selecting features in the dataset. In scikit-learn, you can perform this task in the following steps:\n",
    "\n",
    "- First, create a random forests model.\n",
    "- Second, use the feature importance variable to see feature importance scores.\n",
    "- Third, visualize these scores using the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=200)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,index=feature_cols).sort_values(ascending=False).head(15)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the feature importance\n",
    "\n",
    "For visualization, you can use a combination of `matplotlib` and `seaborn`. Because `seaborn` is built on top of `matplotlib`, it offers a number of customized themes and provides additional plot types. `Matplotlib` is a superset of `seaborn` and both are equally important for good visualizations.\n",
    "\n",
    "__NOTE__: Checking and displaying the feature importances, regardless of applying feature engineering, are always good practices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Model on Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pick the top features\n",
    "# Split dataset into features and labels\n",
    "# Features:\n",
    "fs_X= rfdata[['ExitRatesSkew','ProductRelated_DurationSkew','ProductRelatedSkew',\n",
    "            'Administrative_DurationSkew','BounceRatesSkew','AdministrativeSkew',\n",
    "            'Informational_DurationSkew','SeasonBins_4','InformationalSkew','Region_1',\n",
    "            'TrafficType_2','Browser_2','Weekend_False','Region_3']]        \n",
    "# Labels:\n",
    "fs_y=rfdata['RevenueEnc']    \n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train_fs, X_test_fs, y_train_fs, y_test_fs = train_test_split(fs_X, fs_y, test_size=0.30, random_state=200) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=200)\n",
    "# fit the model with data\n",
    "clf.fit(X_train_fs,y_train_fs)\n",
    "# predict the model\n",
    "y_pred_fs=clf.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After spliting, you will generate a model on the selected training set features, perform predictions on the selected test set features, and compare actual and predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1_Score:\",metrics.f1_score(y_test_fs, y_pred_fs))\n",
    "print(\"AUC:\",metrics.roc_auc_score(y_test_fs, y_pred_fs))\n",
    "print(classification_report(y_test_fs, y_pred_fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __SMOTE Feature Selection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 123) \n",
    "X_train_smote_fs, y_train_smote_fs = sm.fit_sample(X_train_fs, y_train_fs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=200)\n",
    "# fit the model with data\n",
    "clf.fit(X_train_smote_fs,y_train_smote_fs)\n",
    "# predict the model\n",
    "y_pred_smote_fs=clf.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test_fs, y_pred_smote_fs)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"Blues\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1_Score:\",metrics.f1_score(y_test_fs, y_pred_smote_fs))\n",
    "print(\"AUC:\",metrics.roc_auc_score(y_test_fs, y_pred_smote_fs))\n",
    "print(classification_report(y_test_fs, y_pred_smote_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_fs, y_pred_smote_fs))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_fs, y_pred_smote_fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Parameters:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(10, 200).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state = 200)\n",
    "\n",
    "# Create the random search model\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'f1', cv = 3, \n",
    "                        n_iter = 10, verbose = 1, random_state=200)\n",
    "\n",
    "# Fit \n",
    "rs.fit(X_train_smote_fs,y_train_smote_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Apply Parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=200,n_estimators= 48,min_samples_split=5,max_leaf_nodes=37,\n",
    "                          max_features=0.8999999999999999,max_depth=18,bootstrap=True)\n",
    "# fit the model with data\n",
    "clf.fit(X_train_smote_fs,y_train_smote_fs)\n",
    "# predict the model\n",
    "y_pred_smote_fs=clf.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test_fs, y_pred_smote_fs)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1_Score:\",metrics.f1_score(y_test_fs, y_pred_smote_fs))\n",
    "print(\"AUC:\",metrics.roc_auc_score(y_test_fs, y_pred_smote_fs))\n",
    "print(classification_report(y_test_fs, y_pred_smote_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
